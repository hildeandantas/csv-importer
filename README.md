# CSV Importer üöÄ

Este √© um projeto de estudo em Python que oferece uma solu√ß√£o robusta para importar arquivos CSV para um banco de dados PostgreSQL de forma din√¢mica. A aplica√ß√£o utiliza modelos din√¢micos do SQLAlchemy para criar tabelas e colunas em tempo de execu√ß√£o, formatando os nomes e ingerindo os dados de forma eficiente.

## ‚ú® Sobre o Projeto

O principal objetivo do **CSV Importer** √© automatizar o processo de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) para arquivos CSV, eliminando a necessidade de criar manualmente tabelas e scripts de inser√ß√£o para cada novo layout de arquivo. A solu√ß√£o √© orquestrada por uma API constru√≠da com FastAPI, que gerencia o fluxo de forma concisa e eficiente.

### Principais Funcionalidades

  - **API para Upload**: Uma rota `POST /import` para receber arquivos CSV de forma segura.
  - **Detec√ß√£o de Separador**: Identifica automaticamente se o delimitador do CSV √© ponto e v√≠rgula (`;`) ou v√≠rgula (`,`).
  - **Sanitiza√ß√£o de Nomes**: Limpa e formata os nomes das colunas e do arquivo (que se tornar√° o nome da tabela), convertendo-os para o padr√£o `camelCase` e removendo acentos e caracteres especiais.
  - **Cria√ß√£o Din√¢mica de Tabelas**: Utiliza o SQLAlchemy para criar um modelo de dados e a respectiva tabela no banco de dados em tempo de execu√ß√£o, caso ela ainda n√£o exista.
  - **Ingest√£o Eficiente de Dados**: Processa o CSV em *chunks* (peda√ßos) utilizando o Pandas, garantindo um baixo consumo de mem√≥ria mesmo com arquivos muito grandes.
  - **Organiza√ß√£o de Arquivos**: Move os arquivos processados para pastas de sucesso (`ok`) ou erro (`error`) para um controle claro do que foi executado.

## üõ†Ô∏è Tecnologias Utilizadas

  - **Python 3.10+**
  - **FastAPI**: Para a cria√ß√£o da API REST.
  - **SQLAlchemy**: Para o ORM e a conex√£o com o banco de dados.
  - **Pandas**: Para a manipula√ß√£o e leitura eficiente dos arquivos CSV.
  - **PostgreSQL**: Como sistema de gerenciamento de banco de dados.
  - **Uvicorn**: Como servidor ASGI para rodar a aplica√ß√£o FastAPI.

## üìÇ Estrutura do Projeto (Exemplo)

```
.
‚îú‚îÄ‚îÄ app
‚îÇ   ‚îú‚îÄ‚îÄ db
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py         # Inicializa√ß√£o do m√≥dulo de banco de dados
‚îÇ   ‚îú‚îÄ‚îÄ routes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ import_router.py    # Roteamento para importa√ß√£o de arquivos
‚îÇ   ‚îî‚îÄ‚îÄ utils
‚îÇ       ‚îî‚îÄ‚îÄ utils.py             # Fun√ß√µes auxiliares (ex: to_camel_case)
‚îÇ
‚îú‚îÄ‚îÄ temp                        # Pasta tempor√°ria para arquivos
‚îÇ   ‚îú‚îÄ‚îÄ ok/                     # Arquivos processados com sucesso
‚îÇ   ‚îî‚îÄ‚îÄ error/                  # Arquivos que apresentaram erro
‚îÇ
‚îú‚îÄ‚îÄ .env                        # Arquivo para vari√°veis de ambiente (DB_URL)
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias do projeto   
‚îú‚îÄ‚îÄ main.py                     # Arquivo principal da aplica√ß√£o
‚îî‚îÄ‚îÄ README.md                   # Documenta√ß√£o do projeto
```

## üèÅ Como Come√ßar

Siga os passos abaixo para configurar e executar o projeto em seu ambiente local.

### Pr√©-requisitos

  - Python 3.10 ou superior
  - PostgreSQL instalado e rodando
  - Um ambiente virtual (recomendado)

### Instala√ß√£o

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone https://github.com/seu-usuario/csv-importer.git
    cd csv-importer
    ```

2.  **Crie e ative um ambiente virtual:**

    ```bash
    # Para Windows
    python -m venv venv
    .\venv\Scripts\activate

    # Para macOS/Linux
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Instale as depend√™ncias:**

    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure as vari√°veis de ambiente:**
    Crie um arquivo chamado `.env` na raiz do projeto e adicione a URL de conex√£o do seu banco de dados PostgreSQL.

    ```env
    # Exemplo de .env
    DATABASE_URL="postgresql://user:password@host:port/database_name"
    ```

### Executando a Aplica√ß√£o

Com o ambiente configurado, inicie o servidor da API com o Uvicorn:

```bash
uvicorn app.main:app --reload
```

O servidor estar√° dispon√≠vel em `http://127.0.0.1:8000`.

## ‚öôÔ∏è Como Usar

Para importar um arquivo, envie uma requisi√ß√£o `POST` do tipo `multipart/form-data` para a rota `/import`.

### Exemplo com cURL

```bash
curl -X POST -F "file=@/caminho/para/seu/arquivo.csv" http://127.0.0.1:8000/import
```

> **Nota:** Substitua `/caminho/para/seu/arquivo.csv` pelo caminho real do arquivo que voc√™ deseja importar.

## üåä Fluxo de Execu√ß√£o

1.  **Recebimento do Arquivo**: A rota `POST /import` recebe o arquivo via `UploadFile`, valida sua extens√£o (`.csv`) e o salva em uma pasta `./temp`.
2.  **In√≠cio do Processamento**: A API chama a fun√ß√£o principal de processamento, passando o nome do arquivo.
3.  **Limpeza e Formata√ß√£o**:
      - Uma fun√ß√£o auxiliar detecta o separador (`;` ou `,`).
      - Outra fun√ß√£o l√™ o cabe√ßalho, limpa cada nome de coluna usando REGEX para remover acentos e caracteres especiais, e converte para `camelCase`.
      - O nome do arquivo tamb√©m √© convertido para `camelCase` para se tornar o nome da tabela.
4.  **Cria√ß√£o da Tabela**: Uma fun√ß√£o verifica se a tabela j√° existe no banco. Se n√£o, ela cria um modelo din√¢mico do SQLAlchemy com as colunas formatadas (inicialmente como `String`) e gera a tabela no banco.
5.  **Ingest√£o dos Dados**: Utilizando `pd.read_csv` com `chunksize`, os dados do arquivo s√£o lidos em lotes e inseridos na tabela correspondente atrav√©s do m√©todo `to_sql`.
6.  **Finaliza√ß√£o**: Ap√≥s a conclus√£o (com sucesso ou falha), o arquivo √© movido da pasta `./temp` para `./temp/ok` ou `./temp/error`, mantendo um registro do resultado do processamento.

## üéØ Pr√≥ximos Passos e Melhorias

  - [ ] **Detec√ß√£o Din√¢mica de Tipos**: Implementar uma l√≥gica para inferir o tipo de dado de cada coluna (ex: `Integer`, `Float`, `DateTime`) em vez de usar `String` para todas.
  - [ ] **Processamento em Background**: Mover a l√≥gica de processamento de arquivos para um worker em background (ex: Celery, RQ) para que a API retorne uma resposta imediata e n√£o trave com arquivos grandes.
  - [ ] **Testes Unit√°rios**: Adicionar testes para garantir a robustez das fun√ß√µes auxiliares e do fluxo principal.
  - [ ] **Suporte a Outros Formatos**: Estender a solu√ß√£o para suportar outros tipos de arquivos, como Excel (`.xlsx`) ou Parquet.
